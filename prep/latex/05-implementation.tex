\hypertarget{implementation-details}{%
\chapter{Implementation details}\label{implementation-details}}

In this chapter we will cover the implementation of \gls{e3}, which can
be found on \href{https://github.com/e-nikolov/mpyc}{Github}. It is a
fork of \href{https://github.com/lschoe/mpyc}{MPyC} that adds deployment
capabilities. We will now discuss the more critical parts of the
implementation.

\hypertarget{reproducible-development-of-mpyc}{%
\section{Reproducible development of
MPyC}\label{reproducible-development-of-mpyc}}

As previously discussed, the \glspl{vm} of \gls{e3} run the NixOS
distribution of Linux, which is based on the declarative package manager
Nix. One of its benefits is that it can also be used to declaratively
manage the dependencies of a software project via its development shells
feature. Normally such a project would have to explain in its readme how
to install and configure all of the extra tools that are needed for
working with it. On the other hand, with Nix, we can run the command
\texttt{nix\ develop} in a directory containing a declarative
specification in a flake.nix file. This will open a temporary shell
environment and install the specified versions of the dependencies.
Exiting the shell will uninstall them. This process makes it easy to
work on projects that require conflicting versions of packages. To
achieve this, nix does the following:

\begin{itemize}
\tightlist
\item
  it places each build result under \texttt{/nix/store/}, in a
  sub-directory prefixed by the hash of its inputs,
  e.g.~\texttt{/nix/store/2ispfz80kmwrsvwndxkxs56irn86h43p-bash-5.1-p16/}
\item
  nix opens a new shell with a modified \texttt{PATH} environment
  variable that includes the nix store path that contains the new
  package.
\end{itemize}

There are tools like nix-direnv that take dev shells a step further by
automatically loading/unloading the specified dependencies when
entering/leaving a directory that contains a dev shell specification.

\newpage

The entrypoint for Nix in our MPyC fork is the
\href{https://github.com/e-nikolov/mpyc/blob/master/flake.nix}{flake.nix}
file. A simplified version can be seen below:

\begin{Shaded}
\begin{Highlighting}[]

\OperatorTok{\{}
  \VariableTok{description} \OperatorTok{=} \StringTok{"MPyC flake"}\OperatorTok{;}

  \VariableTok{inputs} \OperatorTok{=} \OperatorTok{\{}
    \VariableTok{nixpkgs}\NormalTok{.}\VariableTok{url} \OperatorTok{=} \StringTok{"github:nixos/nixpkgs/nixos{-}unstable"}\OperatorTok{;}
  \OperatorTok{\};}

  \VariableTok{outputs} \OperatorTok{=}\NormalTok{ inputs@}\OperatorTok{\{} \VariableTok{self}\OperatorTok{,} \VariableTok{nixpkgs}\OperatorTok{,} \OperatorTok{...} \OperatorTok{\}}\NormalTok{:}
    \KeywordTok{let}
      \CommentTok{\# import the derivation of mpyc and all of its python dependencies}
      \VariableTok{mpyc{-}demo} \OperatorTok{=} \OperatorTok{(}\BuiltInTok{import} \SpecialStringTok{./nix/mpyc{-}demo.nix} \OperatorTok{\{} \KeywordTok{inherit}\NormalTok{ pkgs}\OperatorTok{;} \VariableTok{dir} \OperatorTok{=} \SpecialStringTok{./.}\OperatorTok{;} \OperatorTok{\});}

      \VariableTok{pkgs} \OperatorTok{=} \BuiltInTok{import}\NormalTok{ nixpkgs }\OperatorTok{\{}
        \VariableTok{system} \OperatorTok{=} \StringTok{"x86\_64{-}linux"}\OperatorTok{;}
      \OperatorTok{\};}
    \KeywordTok{in}
    \OperatorTok{\{}
      \VariableTok{devShell}\NormalTok{.}\VariableTok{x86\_64{-}linux} \OperatorTok{=}\NormalTok{ pkgs.mkShell }\OperatorTok{\{}
        \VariableTok{shellHook} \OperatorTok{=} \StringTok{\textquotesingle{}\textquotesingle{}}
\StringTok{          export PYTHONPATH=./}
\StringTok{        \textquotesingle{}\textquotesingle{}}\OperatorTok{;}
        
        \VariableTok{nativeBuildInputs} \OperatorTok{=} \OperatorTok{[}
\NormalTok{          pkgs.curl pkgs.jq}
\NormalTok{          pkgs.colmena pkgs.pssh}
          \OperatorTok{(}\NormalTok{pkgs.terraform.withPlugins}
            \OperatorTok{(}\VariableTok{tp}\OperatorTok{:} \OperatorTok{[}
\NormalTok{              tp.digitalocean tp.}\ConstantTok{null}
\NormalTok{              tp.external tp.tailscale}
\NormalTok{              tp.random}
            \OperatorTok{]))}
\NormalTok{          mpyc{-}demo}
        \OperatorTok{];}
      \OperatorTok{\};}
    \OperatorTok{\};}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

The flake is functionally pure in the sense that all external inputs are
explicitly declared in the inputs section and their hashes are kept in a
\texttt{flake.lock} file. In our example, the only input is
\texttt{nixpkgs} - a community managed repository containing the nix
build expressions for more than 80 000 packages. When a nix command uses
the file for the first time, the latest revision of the nixos-unstable
branch of the git repository will be fetched and its contents will be
hashed and placed in the flake.lock. Further executions will reuse the
revision from the lock file and verify that the resulting hash matches
the original one. The lock file can be updated via the
\texttt{nix\ flake\ update} command. The output section contains the
\texttt{devShell.x86\_64-linux} attribute which declares the packages
required to work with the project. Specifically, it needs the nix
packages for curl, jq, colmena, pssh and terraform with a number of
plugins. Finally it also builds the \texttt{mpyc-demo} package which
contains python and all python dependencies needed by MPyC. Its
specification is imported from the \texttt{mpyc-demo.nix} file:

\newpage

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{\{} \VariableTok{pkgs}\OperatorTok{,} \VariableTok{dir} \OperatorTok{\}}\NormalTok{:}
\OperatorTok{(}\NormalTok{pkgs.poetry2nix.mkPoetryEnv }\OperatorTok{\{}
    \VariableTok{python} \OperatorTok{=}\NormalTok{ pkgs.python3}\OperatorTok{;}
    \VariableTok{projectDir} \OperatorTok{=}\NormalTok{ dir}\OperatorTok{;}

    \VariableTok{extraPackages} \OperatorTok{=} \OperatorTok{(}\VariableTok{ps}\OperatorTok{:} \OperatorTok{[}
      \OperatorTok{(}\NormalTok{pkgs.python3Packages.buildPythonPackage}
        \OperatorTok{\{}
          \VariableTok{name} \OperatorTok{=} \StringTok{"mpyc"}\OperatorTok{;}
          \VariableTok{src} \OperatorTok{=}\NormalTok{ dir}\OperatorTok{;}
        \OperatorTok{\})}
    \OperatorTok{]);}

    \VariableTok{overrides} \OperatorTok{=}\NormalTok{ pkgs.poetry2nix.overrides.withDefaults }\OperatorTok{(}
      \VariableTok{self}\OperatorTok{:} \VariableTok{super}\OperatorTok{:} \OperatorTok{\{}
        \VariableTok{gmpy2} \OperatorTok{=}\NormalTok{ pkgs.python3Packages.gmpy2}\OperatorTok{;}
      \OperatorTok{\}}
    \OperatorTok{);}
  \OperatorTok{\})}
\end{Highlighting}
\end{Shaded}

MPyC uses the python specific dependency management tool
poetry\autocite{poetryDocs} and the poetry2nix package dynamically
generates nix expressions from its configuration in
\texttt{pyproject.toml}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{[}\DataTypeTok{tool}\KeywordTok{.}\DataTypeTok{poetry}\KeywordTok{]}
\DataTypeTok{name} \OperatorTok{=} \StringTok{"mpyc"}
\DataTypeTok{version} \OperatorTok{=} \StringTok{"0.8.8"}
\DataTypeTok{description} \OperatorTok{=} \StringTok{"MPyC for Multiparty Computation in Python"}
\DataTypeTok{authors} \OperatorTok{=} \OperatorTok{[}\StringTok{"Berry Schoenmakers \textless{}berry@win.tue.nl\textgreater{}"}\OperatorTok{]}
\DataTypeTok{readme} \OperatorTok{=} \StringTok{"README.md"}
\DataTypeTok{packages} \OperatorTok{=} \OperatorTok{[\{}\DataTypeTok{include}\OperatorTok{ =} \StringTok{"demos"}\OperatorTok{\}]}

\KeywordTok{[}\DataTypeTok{tool}\KeywordTok{.}\DataTypeTok{poetry}\KeywordTok{.}\DataTypeTok{dependencies}\KeywordTok{]}
\DataTypeTok{python} \OperatorTok{=} \StringTok{"\^{}3.10"}
\DataTypeTok{qrcode} \OperatorTok{=} \StringTok{"\^{}7.3.1"}
\DataTypeTok{numpy} \OperatorTok{=} \StringTok{"\^{}1.23.4"}
\DataTypeTok{gmpy2} \OperatorTok{=} \StringTok{"\^{}2.1.2"}

\KeywordTok{[}\DataTypeTok{build{-}system}\KeywordTok{]}
\DataTypeTok{requires} \OperatorTok{=} \OperatorTok{[}\StringTok{"poetry{-}core"}\OperatorTok{]}
\DataTypeTok{build{-}backend} \OperatorTok{=} \StringTok{"poetry.core.masonry.api"}
\end{Highlighting}
\end{Shaded}

There was an issue with the gmpy2 library when building it via
poetry2nix, but fortunately we could override it with the version
already present in nixpkgs.

Using this setup we can now go to the root directory of MPyC and run the
\texttt{nix\ develop} command, which will automatically download, build
and install all of our dependencies in a temporary shell. We are then
ready to make changes to MPyC or locally run the demos, e.g.~via
\texttt{python\ ./demos/secretsanta.py}.

\hypertarget{building-a-nixos-image-for-digitalocean}{%
\section{Building a NixOS image for
DigitalOcean}\label{building-a-nixos-image-for-digitalocean}}

As previously discussed we will deploy \gls{e3} on DigitalOcean droplets
- their name for \glspl{vm}. They do not provide an official NixOS
image, but we can build our own using nix.

\newpage

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# flake.nix}

\OperatorTok{\{}
  \VariableTok{inputs} \OperatorTok{=} \OperatorTok{\{}
    \VariableTok{nixpkgs}\NormalTok{.}\VariableTok{url} \OperatorTok{=} \StringTok{"github:nixos/nixpkgs/nixos{-}unstable"}\OperatorTok{;}
  \OperatorTok{\};}

  \VariableTok{outputs} \OperatorTok{=}\NormalTok{ inputs@}\OperatorTok{\{} \VariableTok{self}\OperatorTok{,} \VariableTok{nixpkgs}\OperatorTok{,} \OperatorTok{...} \OperatorTok{\}}\NormalTok{:}
    \KeywordTok{let}
      \VariableTok{mpyc{-}demo} \OperatorTok{=} \OperatorTok{(}\BuiltInTok{import} \SpecialStringTok{./nix/mpyc{-}demo.nix} \OperatorTok{\{} \KeywordTok{inherit}\NormalTok{ pkgs}\OperatorTok{;} \VariableTok{dir} \OperatorTok{=} \SpecialStringTok{./.}\OperatorTok{;} \OperatorTok{\});}

      \VariableTok{pkgs} \OperatorTok{=} \BuiltInTok{import}\NormalTok{ nixpkgs }\OperatorTok{\{}
        \VariableTok{system} \OperatorTok{=} \StringTok{"x86\_64{-}linux"}\OperatorTok{;}
      \OperatorTok{\};}

      \VariableTok{digitalOceanConfig} \OperatorTok{=} \BuiltInTok{import} \SpecialStringTok{./nix/digitalocean/image.nix} \OperatorTok{\{}
        \KeywordTok{inherit}\NormalTok{ pkgs}\OperatorTok{;}
        \VariableTok{extraPackages} \OperatorTok{=} \OperatorTok{[}\NormalTok{ mpyc{-}demo }\OperatorTok{];}
      \OperatorTok{\};}
    \KeywordTok{in}
    \OperatorTok{\{}
        \VariableTok{packages}\NormalTok{.}\VariableTok{digitalOceanImage} \OperatorTok{=} \OperatorTok{(}\NormalTok{pkgs.nixos digitalOceanConfig}\OperatorTok{)}\NormalTok{.digitalOceanImage}\OperatorTok{;}
    \OperatorTok{\};}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# nix/digitalocean/image.nix}

\OperatorTok{\{} \VariableTok{pkgs}\OperatorTok{,} \VariableTok{extraPackages} \OperatorTok{?} \OperatorTok{[} \OperatorTok{],} \OperatorTok{...} \OperatorTok{\}}\NormalTok{:}
\OperatorTok{\{}
  \VariableTok{imports} \OperatorTok{=} \OperatorTok{[} \StringTok{"}\SpecialCharTok{$\{}\NormalTok{pkgs.path}\SpecialCharTok{\}}\StringTok{/nixos/modules/virtualisation/digital{-}ocean{-}image.nix"} \OperatorTok{];}
  \VariableTok{system}\NormalTok{.}\VariableTok{stateVersion} \OperatorTok{=} \StringTok{"22.11"}\OperatorTok{;}

  \VariableTok{environment}\NormalTok{.}\VariableTok{systemPackages} \OperatorTok{=} \KeywordTok{with}\NormalTok{ pkgs}\OperatorTok{;} \OperatorTok{[}
\NormalTok{    jq}
  \OperatorTok{]} \OperatorTok{++}\NormalTok{ extraPackages}\OperatorTok{;}

  \VariableTok{services}\NormalTok{.}\VariableTok{tailscale}\NormalTok{.}\VariableTok{enable} \OperatorTok{=} \ConstantTok{true}\OperatorTok{;}

  \VariableTok{networking}\NormalTok{.}\VariableTok{firewall} \OperatorTok{=} \OperatorTok{\{}
    \VariableTok{enable} \OperatorTok{=} \ConstantTok{true}\OperatorTok{;}
    \VariableTok{checkReversePath} \OperatorTok{=} \StringTok{"loose"}\OperatorTok{;}
    \VariableTok{trustedInterfaces} \OperatorTok{=} \OperatorTok{[} \StringTok{"tailscale0"} \OperatorTok{];}
  \OperatorTok{\};}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

The image is based on the default version provided by nixpkgs and adds
some extra packages and configurations. It:

\begin{itemize}
\tightlist
\item
  enables the tailscale service so that we can easily configure them to
  join the same tailscale network;
\item
  configures the firewall to allow tailscale traffic;
\item
  includes the \texttt{mpyc-demo} package we made earlier for the
  development shell.
\end{itemize}

The image will likely be built only once, but it is still useful to have
even an outdated version of the demo baked into it as it helps us avoid
having to build all of the python dependencies while deploying later.

Running \texttt{nix\ build\ .\#packages.digitalOceanImage} creates a
\texttt{.qcow2.gz} formatted image file that can be imported into
DigitalOcean.

\hypertarget{building-a-nixos-image-for-raspberrypi}{%
\section{Building a NixOS image for
RaspberryPi}\label{building-a-nixos-image-for-raspberrypi}}

We can build a NixOS image for a RaspberryPi4 with a similar nix
expression:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{\{}
  \VariableTok{inputs} \OperatorTok{=} \OperatorTok{\{}
    \VariableTok{nixpkgs}\NormalTok{.}\VariableTok{url} \OperatorTok{=} \StringTok{"github:nixos/nixpkgs/nixos{-}unstable"}\OperatorTok{;}
  \OperatorTok{\};}

  \VariableTok{outputs} \OperatorTok{=}\NormalTok{ inputs@}\OperatorTok{\{} \VariableTok{self}\OperatorTok{,} \VariableTok{nixpkgs}\OperatorTok{,} \OperatorTok{...} \OperatorTok{\}}\NormalTok{:}
    \KeywordTok{let}
      \VariableTok{mpyc{-}demo} \OperatorTok{=} \OperatorTok{(}\BuiltInTok{import} \SpecialStringTok{./nix/mpyc{-}demo.nix} \OperatorTok{\{} \KeywordTok{inherit}\NormalTok{ pkgs}\OperatorTok{;} \VariableTok{dir} \OperatorTok{=} \SpecialStringTok{./.}\OperatorTok{;} \OperatorTok{\});}

      \VariableTok{pkgs} \OperatorTok{=} \BuiltInTok{import}\NormalTok{ nixpkgs }\OperatorTok{\{}
        \VariableTok{system} \OperatorTok{=} \StringTok{"aarch64{-}linux"}\OperatorTok{;}
      \OperatorTok{\};}
    \KeywordTok{in}
    \OperatorTok{\{}
        \VariableTok{packages}\NormalTok{.}\VariableTok{raspberryPi4Image} \OperatorTok{=} \OperatorTok{(}\NormalTok{pkgs.nixos }\OperatorTok{(\{} \VariableTok{config}\OperatorTok{,} \OperatorTok{...} \OperatorTok{\}}\NormalTok{: }\OperatorTok{\{}
            \VariableTok{system}\NormalTok{.}\VariableTok{stateVersion} \OperatorTok{=} \StringTok{"22.11"}\OperatorTok{;}
            \VariableTok{imports} \OperatorTok{=} \OperatorTok{[}
              \OperatorTok{(}\StringTok{"}\SpecialCharTok{$\{}\NormalTok{pkgs.path}\SpecialCharTok{\}}\StringTok{/nixos/modules/installer/sd{-}card/sd{-}image{-}aarch64{-}installer.nix"}\OperatorTok{)}
            \OperatorTok{];}
            
            \VariableTok{environment}\NormalTok{.}\VariableTok{systemPackages} \OperatorTok{=} \OperatorTok{[}
\NormalTok{                mpyc{-}demo}
            \OperatorTok{];}
        \OperatorTok{\}))}\NormalTok{.sdImage}\OperatorTok{;}
    \OperatorTok{\};}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

The build command has to be executed on an ARM64 based processor in
order to succeed. This can be achieved either via emulation with qemu
binfmt or via a virtual machine. When already running NixOS as a host,
all that is required is to add
\texttt{extra-platforms\ =\ aarch64-linux} to the
\texttt{/etc/nixos/nix.conf} file.

\hypertarget{provisioning-via-terraform}{%
\section{Provisioning via Terraform}\label{provisioning-via-terraform}}

We will provision DigitalOcean droplets with Terraform from the VM image
created earlier. We need to provide it with a DigitalOcean authorization
key in the \texttt{DIGITALOCEAN\_TOKEN} environment variable so it can
use their API on our behalf.

\hypertarget{importing-the-image}{%
\subsubsection{Importing the image}\label{importing-the-image}}

The snippet below handles the upload of our NixOS image.

\newpage

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{variable "nixos{-}image{-}path" \{}
\NormalTok{  type    = string}
\NormalTok{  default = "../../bin/image/nixos.qcow2.gz"}
\NormalTok{\}}

\NormalTok{resource "digitalocean\_spaces\_bucket" "tf{-}state" \{}
\NormalTok{  name   = "mpyc{-}tf{-}state"}
\NormalTok{  region = "ams3"}

\NormalTok{  lifecycle \{}
\NormalTok{    prevent\_destroy = true}
\NormalTok{  \}}
\NormalTok{\}}

\NormalTok{resource "digitalocean\_spaces\_bucket\_object" "nixos{-}image" \{}
\NormalTok{  region = digitalocean\_spaces\_bucket.tf{-}state.region}
\NormalTok{  bucket = digitalocean\_spaces\_bucket.tf{-}state.name}
\NormalTok{  key    = basename(var.nixos{-}image{-}path)}
\NormalTok{  source = var.nixos{-}image{-}path}
\NormalTok{  acl    = "public{-}read"}
\NormalTok{  etag   = filemd5(var.nixos{-}image{-}path)}
\NormalTok{\}}

\NormalTok{resource "digitalocean\_custom\_image" "nixos{-}image" \{}
\NormalTok{  name    = "nixos{-}22.11"}
\NormalTok{  url     = "https://$\{digitalocean\_spaces\_bucket.tf{-}state.bucket\_domain\_name\}/$\{digitalocean\_spaces\_bucket\_object.nixos{-}image.key\}"}
\NormalTok{  regions = local.all\_regions}
\NormalTok{  tags    = ["nixos"]}

\NormalTok{  lifecycle \{}
\NormalTok{    replace\_triggered\_by = [}
\NormalTok{      digitalocean\_spaces\_bucket\_object.nixos{-}image}
\NormalTok{    ]}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

The DigitalOcean API only supports importing images from a URL, so we
first need to upload the image to a publicly accessible location. For
that purpose, the snippet above first provisions a Bucket within Spaces
- DigitalOcean's cloud storage solution and uploads the image there.
After that, the \texttt{digitalocean\_custom\_image} will import the
image from the URL generated by the bucket.

\hypertarget{generating-hostnames}{%
\subsubsection{Generating hostnames}\label{generating-hostnames}}

The snippet below starts with a specification of how many machines per
region we want to have and transforms it into a list of descriptive ids
(e.g.~\texttt{mpyc-demo-\/-ams3-0-15e53f39}) that will be used as host
names so we can easily distinguish the machines when they start
communicating with each other.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{locals \{}
\NormalTok{  node\_definitions = var.DESTROY\_NODES != "" ? [}
\NormalTok{    \{ region = "ams3", num = 0 \},}
\NormalTok{    \{ region = "sfo3", num = 0 \},}
\NormalTok{    \{ region = "nyc3", num = 0 \},}
\NormalTok{    \{ region = "sgp1", num = 0 \},}
\NormalTok{    ] : [}
\NormalTok{    \{ region = "ams3", num = 3 \},}
\NormalTok{    \{ region = "sfo3", num = 1 \},}
\NormalTok{    \{ region = "nyc3", num = 1 \},}
\NormalTok{    \{ region = "sgp1", num = 1 \},}
\NormalTok{  ]}

\NormalTok{  nodes\_expanded = flatten([}
\NormalTok{    for node in local.node\_definitions : [}
\NormalTok{      for i in range(node.num) :}
\NormalTok{      merge(node, \{}
\NormalTok{        name = "mpyc{-}demo{-}{-}$\{node.region\}{-}$\{i\}"}
\NormalTok{      \})}
\NormalTok{    ]}
\NormalTok{  ])}

\NormalTok{  nodes = \{}
\NormalTok{    for node in local.nodes\_expanded :}
\NormalTok{    node.name =\textgreater{} merge(node, \{}
\NormalTok{      hostname = "$\{node.name\}{-}$\{random\_id.mpyc{-}node{-}hostname[node.name].hex\}"}
\NormalTok{    \})}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{provisioning-the-hosts}{%
\subsubsection{Provisioning the hosts}\label{provisioning-the-hosts}}

The snippet below provisions the droplets in the specified regions and
then using Tailscale's terraform provider creates auth keys for the
machines, copies them to the machines and configures them to join the
tailscale network. When the droplets are being destroyed, the
provisioner will remove the nodes from the network.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{resource "digitalocean\_droplet" "mpyc{-}node" \{}
\NormalTok{  for\_each = local.nodes}

\NormalTok{  image    = digitalocean\_custom\_image.nixos{-}image.id}
\NormalTok{  name     = each.value.hostname}
\NormalTok{  region   = each.value.region}
\NormalTok{  size     = "s{-}1vcpu{-}1gb"}
\NormalTok{  ssh\_keys = [for key in digitalocean\_ssh\_key.ssh{-}keys : key.fingerprint]}

\NormalTok{  connection \{}
\NormalTok{    type = "ssh"}
\NormalTok{    user = "root"}
\NormalTok{    host = self.ipv4\_address}
\NormalTok{  \}}

\NormalTok{  provisioner "remote{-}exec" \{}
\NormalTok{    inline = [}
\NormalTok{      "mkdir {-}p /var/keys/",}
\NormalTok{      "echo $\{tailscale\_tailnet\_key.keys.key\} \textgreater{} /var/keys/tailscale",}
\NormalTok{      "tailscale up {-}{-}auth{-}key file:/var/keys/tailscale"}
\NormalTok{    ]}
\NormalTok{  \}}

\NormalTok{  provisioner "remote{-}exec" \{}
\NormalTok{    when = destroy}
\NormalTok{    inline = [}
\NormalTok{      "tailscale logout"}
\NormalTok{    ]}
\NormalTok{  \}}

\NormalTok{  lifecycle \{}
\NormalTok{    replace\_triggered\_by = [}
\NormalTok{      tailscale\_tailnet\_key.keys}
\NormalTok{    ]}
\NormalTok{  \}}
\NormalTok{\}}

\NormalTok{resource "tailscale\_tailnet\_key" "keys" \{}
\NormalTok{  reusable      = true}
\NormalTok{  ephemeral     = true}
\NormalTok{  preauthorized = true}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{interfacing-with-other-tools}{%
\subsubsection{Interfacing with other
tools}\label{interfacing-with-other-tools}}

This snippet outputs the hostnames of the provisioned droplets so they
can be picked up by other tools. For example Colmena will read them from
a json file so it can deploy further software changes to them.

\begin{Shaded}
\begin{Highlighting}[]


\NormalTok{output "hosts{-}colmena" \{}
\NormalTok{  value = \{ for node in local.nodes : node.hostname =\textgreater{} \{\} \}}
\NormalTok{\}}

\NormalTok{output "hosts{-}pssh" \{}
\NormalTok{  value = join("", [for node in local.nodes : "root@$\{node.hostname\}\textbackslash{}n"])}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{colmena-deployment}{%
\section{Colmena deployment}\label{colmena-deployment}}

Whenever we need to update the NixOS configuration of our VMs, we could
rebuild the image and re-provision them, but this would be slow. Instead
we use Colmena to deploy and apply the new configuration to all existing
VMs. It uses the same \texttt{digitalOceanConfig} attribute we created
for the NixOS image:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{\{}
  \VariableTok{inputs} \OperatorTok{=} \OperatorTok{\{}
    \VariableTok{nixpkgs}\NormalTok{.}\VariableTok{url} \OperatorTok{=} \StringTok{"github:nixos/nixpkgs/nixos{-}unstable"}\OperatorTok{;}
  \OperatorTok{\};}

  \VariableTok{outputs} \OperatorTok{=}\NormalTok{ inputs@}\OperatorTok{\{} \VariableTok{self}\OperatorTok{,} \VariableTok{nixpkgs}\OperatorTok{,} \OperatorTok{...} \OperatorTok{\}}\NormalTok{:}
    \KeywordTok{let}
      \VariableTok{mpyc{-}demo} \OperatorTok{=} \OperatorTok{(}\BuiltInTok{import} \SpecialStringTok{./nix/mpyc{-}demo.nix} \OperatorTok{\{} \KeywordTok{inherit}\NormalTok{ pkgs}\OperatorTok{;} \VariableTok{dir} \OperatorTok{=} \SpecialStringTok{./.}\OperatorTok{;} \OperatorTok{\});}

      \VariableTok{pkgs} \OperatorTok{=} \BuiltInTok{import}\NormalTok{ nixpkgs }\OperatorTok{\{}
        \VariableTok{system} \OperatorTok{=} \StringTok{"x86\_64{-}linux"}\OperatorTok{;}
      \OperatorTok{\};}

      \VariableTok{digitalOceanConfig} \OperatorTok{=} \BuiltInTok{import} \SpecialStringTok{./nix/digitalocean/image.nix} \OperatorTok{\{}
        \KeywordTok{inherit}\NormalTok{ pkgs}\OperatorTok{;}
        \VariableTok{extraPackages} \OperatorTok{=} \OperatorTok{[}\NormalTok{ mpyc{-}demo }\OperatorTok{];}
      \OperatorTok{\};}
    \KeywordTok{in}
    \OperatorTok{\{}
      \VariableTok{packages}\NormalTok{.}\VariableTok{colmena} \OperatorTok{=} \OperatorTok{\{}
        \VariableTok{meta} \OperatorTok{=} \OperatorTok{\{}
          \VariableTok{nixpkgs} \OperatorTok{=}\NormalTok{ pkgs}\OperatorTok{;}
        \OperatorTok{\};}
        \VariableTok{defaults} \OperatorTok{=}\NormalTok{ digitalOceanConfig}\OperatorTok{;}
      \OperatorTok{\}} \OperatorTok{//} \BuiltInTok{builtins}\NormalTok{.fromJSON }\OperatorTok{(}\BuiltInTok{builtins}\NormalTok{.readFile }\SpecialStringTok{./hosts.json}\OperatorTok{);}
    \OperatorTok{\};}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

This allows us to quickly make changes to the NixOS configuration,
deploy it via Colmena and once we are satisfied with it, we can choose
to rebuild the image so that new machines get provisioned with all of
our changes baked in.

\hypertarget{runtime-execution}{%
\section{Runtime execution}\label{runtime-execution}}

We have identified the tools we will use to deploy \gls{e3} and how the
host machines will communicate. What remains is to determine how to run
a joint computation on the hosts. When running such an experiment, it
would be desirable to be able to iterate quickly. Colmena can be used to
deploy a new version of the whole operating system, but it would be
unnecessary to rebuild all dependencies every time we want to run a
command. Therefore we decided to use two additional tools:

\begin{itemize}
\tightlist
\item
  \emph{prsync} - a variant of the popular \emph{rsync} utility that can
  additively sync the contents of a directory to multiple remote hosts
\item
  \emph{pssh} - a tool for executing an ssh command on many hosts in
  parallel
\end{itemize}

An example execution looks like this:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{prsync} \AttributeTok{{-}h}\NormalTok{ hosts.pssh }\AttributeTok{{-}zarv} \AttributeTok{{-}p}\NormalTok{ 4 ./ /root/mpyc}
\ExtensionTok{pssh} \AttributeTok{{-}h}\NormalTok{ hosts.pssh }\AttributeTok{{-}iv} \AttributeTok{{-}o}\NormalTok{ ./logs/}\VariableTok{$t} \StringTok{"cd /root/mpyc \&\& ./prun.sh"}
\end{Highlighting}
\end{Shaded}

It loads the hostnames from the \texttt{hosts.pssh} file that was
previously generated by terraform and syncs the current state of the
mpyc directory. The second line will execute the \texttt{prun.sh} script
on each host.

An example of a possible \texttt{prun.sh} script:

\newpage

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#!/bin/sh}

\VariableTok{MAX\_PARTIES}\OperatorTok{=}\NormalTok{600}
\VariableTok{hosts}\OperatorTok{=}\StringTok{"./hosts.pssh"}
\VariableTok{port}\OperatorTok{=}\NormalTok{11599}

\VariableTok{i}\OperatorTok{=}\NormalTok{0}
\VariableTok{MY\_PID}\OperatorTok{=}\NormalTok{{-}1}

\VariableTok{args}\OperatorTok{=}\StringTok{""}
\ControlFlowTok{while} \VariableTok{IFS}\OperatorTok{=} \BuiltInTok{read} \AttributeTok{{-}r} \VariableTok{line}
\ControlFlowTok{do}
    \ControlFlowTok{if} \BuiltInTok{[} \VariableTok{$i} \OtherTok{{-}ge} \VariableTok{$MAX\_PARTIES} \BuiltInTok{]}
    \ControlFlowTok{then}
        \ControlFlowTok{break}
    \ControlFlowTok{fi}
    \ControlFlowTok{if} \BuiltInTok{[} \OtherTok{{-}z} \StringTok{"}\VariableTok{$line}\StringTok{"} \BuiltInTok{]}
    \ControlFlowTok{then} 
        \ControlFlowTok{break}
    \ControlFlowTok{fi}

    \VariableTok{host}\OperatorTok{=}\VariableTok{$\{line}\OperatorTok{\#}\StringTok{"root@"}\VariableTok{\}}

    \ControlFlowTok{if} \BuiltInTok{[} \StringTok{"}\VariableTok{$host}\StringTok{"} \OtherTok{=} \StringTok{"}\VariableTok{$HOSTNAME}\StringTok{"} \BuiltInTok{]}
    \ControlFlowTok{then}
        \VariableTok{MY\_PID}\OperatorTok{=}\VariableTok{$i}
    \ControlFlowTok{fi}
    \KeywordTok{((}\VariableTok{i} \OperatorTok{=} \VariableTok{i} \OperatorTok{+} \DecValTok{1}\KeywordTok{))}

    \VariableTok{args}\OperatorTok{+=}\StringTok{" {-}P }\VariableTok{$host}\StringTok{:}\VariableTok{$port}\StringTok{"} 
\ControlFlowTok{done} \OperatorTok{\textless{}} \StringTok{"}\VariableTok{$hosts}\StringTok{"}

\ControlFlowTok{if} \BuiltInTok{[} \VariableTok{$MY\_PID} \OtherTok{=}\NormalTok{ {-}1 }\BuiltInTok{]}
\ControlFlowTok{then}
    \BuiltInTok{echo}\NormalTok{ Only }\VariableTok{$i}\NormalTok{ parties are allowed. }\VariableTok{$HOSTNAME}\NormalTok{ will not participate in this MPC session}
\ControlFlowTok{else}

\VariableTok{cmd}\OperatorTok{=}\StringTok{"python ./demos/secretsanta.py 3 {-}{-}log{-}level debug }\DataTypeTok{\textbackslash{}}
\StringTok{    {-}I }\VariableTok{$\{MY\_PID\}}\StringTok{ }\DataTypeTok{\textbackslash{}}
\StringTok{    }\VariableTok{$\{args\}}\StringTok{"}

\BuiltInTok{echo} \VariableTok{$cmd}
\VariableTok{$cmd}

\ControlFlowTok{fi}
\end{Highlighting}
\end{Shaded}

Each host runs the same script that builds the arguments for the
\texttt{secretsanta.py} demo of MPyC. Each party determines its own
Party ID based on the index at which its hostname appears in the
\texttt{hosts.pssh} file.

\hypertarget{secrets}{%
\section{Secrets}\label{secrets}}

The implementation expects that secrets are supplied as environment
variables with the specific mechanism being left up to the user. We are
currently keeping the secret values in the 1Password manager and use its
\gls{cli} to populate the environment variables at runtime, e.g.~via
\texttt{op\ run\ -\/-\ make\ deploy}.
